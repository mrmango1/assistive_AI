# ğŸ¦¯ Assistive Voice App

Asistente de voz asistivo para personas ciegas. Usa comandos de voz en espaÃ±ol para leer documentos o describir el entorno con ayuda de inteligencia artificial.

---

## âœ… CaracterÃ­sticas

- **Reconocimiento de voz offline** con **Vosk** para escucha continua
- **OCR inteligente** con dos opciones:
  - **OpenAI GPT-4 Vision** (mayor precisiÃ³n, requiere internet)
  - **Tesseract OCR** (funciona sin internet)
- **DescripciÃ³n de escenas** mediante **OpenAI GPT-4 Vision**
- **SÃ­ntesis de voz avanzada** con tres opciones:
  - **OpenAI TTS** (voz natural de alta calidad)
  - **Coqui TTS** (voz neural offline)
  - **TTS del sistema** (espeak/say como fallback)
- **DetecciÃ³n automÃ¡tica de conectividad** con fallback inteligente
- **Comandos personalizables** con coincidencias aproximadas
- **Manejo inteligente de errores** y limpieza automÃ¡tica de archivos temporales

---

## ğŸ“¦ Requisitos

- Python 3.10 o superior
- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)
- Modelo Vosk en espaÃ±ol
- Clave API de OpenAI (opcional, para mejor calidad)
- LibrerÃ­as Python (ver `requirements.txt`)

---

## ğŸ”§ InstalaciÃ³n

### 1. Clona el proyecto y entra al directorio

```bash
git clone https://github.com/tu-usuario/assistive_ai.git
cd assistive_ai
```

### 2. Crea y activa el entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instala las dependencias

```bash
pip install -r requirements.txt
```

### 4. Instala Tesseract (requerido)

**En macOS:**

```bash
brew install tesseract
```

**En Raspberry Pi/Linux:**

```bash
sudo apt update && sudo apt install tesseract-ocr tesseract-ocr-spa
```

### 5. Instala herramientas de audio adicionales (opcional)

**En macOS:** Ya incluidas

**En Linux/Raspberry Pi:**

```bash
sudo apt install espeak espeak-data mpg123 ffmpeg
```

---

## ğŸ™ï¸ ConfiguraciÃ³n de Vosk

1. Descarga el modelo en espaÃ±ol desde:  
   [https://alphacephei.com/vosk/models](https://alphacephei.com/vosk/models)

   **Modelo recomendado:** `vosk-model-small-es-0.42`

2. Extrae el modelo y colÃ³calo en la carpeta `models/`:

   ```
   assistive_ai/
   â””â”€â”€ models/
       â””â”€â”€ vosk-model-small-es-0.42/
           â”œâ”€â”€ am/
           â”œâ”€â”€ graph/
           â”œâ”€â”€ ivector/
           â””â”€â”€ conf/
   ```

---

## ğŸ¤– ConfiguraciÃ³n de OpenAI (Opcional)

Para mejor calidad en OCR, descripciÃ³n de imÃ¡genes y sÃ­ntesis de voz:

1. ObtÃ©n una clave API de [OpenAI](https://platform.openai.com/api-keys)

2. Configura la variable de entorno:

   ```bash
   export OPENAI_API_KEY="tu-clave-api-aqui"
   ```

3. O edita directamente `config.py`:

   ```python
   OPENAI_API_KEY = "tu-clave-api-aqui"
   ```

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

Edita `config.py` para personalizar el comportamiento:

```python
# ConfiguraciÃ³n de OCR
USE_OPENAI_OCR = True    # False para usar solo Tesseract

# ConfiguraciÃ³n de TTS  
USE_OPENAI_TTS = True    # False para usar Coqui/Sistema

# ConfiguraciÃ³n de idioma
LANGUAGE = "spa"         # Idioma para Tesseract

# Timeouts
API_REQUEST_TIMEOUT = 30
INTERNET_CHECK_TIMEOUT = 3
```

---

## ğŸš€ EjecuciÃ³n

```bash
python main.py
```

**Salida esperada:**

```
Iniciando asistente de voz...
ConfiguraciÃ³n - OCR: OpenAI
ConfiguraciÃ³n - TTS: OpenAI
Inicializando reconocedor de voz...
Modelo Vosk cargado exitosamente.
Configurando escucha de audio...
Escuchando continuamente con Vosk...
Asistente listo. Di un comando para comenzar.
```

---

## ğŸ—£ï¸ Comandos Disponibles

### Comandos por defecto

| AcciÃ³n | Frases de ejemplo |
|--------|-------------------|
| **Leer documento** | "leer documento", "quiero que leas", "lee esto" |
| **Describir escena** | "describir escena", "quÃ© ves", "dime quÃ© hay aquÃ­" |
| **Salir** | "salir", "terminar", "adiÃ³s", "cerrar" |

### Personalizar comandos

Crea o edita el archivo `commands.json`:

```json
{
  "read_document": [
    "leer documento", "quiero que leas", "puedes leer esto",
    "lee esto", "lee el documento", "leer texto"
  ],
  "describe_scene": [
    "describir escena", "quÃ© ves", "descrÃ­beme el lugar", 
    "describe la imagen", "quÃ© hay aquÃ­", "dime quÃ© ves"
  ],
  "exit": ["salir", "terminar", "adiÃ³s", "bye", "cerrar"]
}
```

---

## ğŸ”„ Modos de Funcionamiento

### Con Internet (Modo Completo)

- **OCR:** OpenAI GPT-4 Vision (alta precisiÃ³n)
- **TTS:** OpenAI TTS (voz natural)
- **DescripciÃ³n:** OpenAI GPT-4 Vision

### Sin Internet (Modo Offline)

- **OCR:** Tesseract (funcional)
- **TTS:** Coqui TTS o sistema (espeak/say)
- **DescripciÃ³n:** No disponible

### Modo HÃ­brido

- El asistente detecta automÃ¡ticamente la conectividad
- Cambia entre modos segÃºn disponibilidad
- Informa al usuario quÃ© mÃ©todo estÃ¡ usando

---

## ğŸ› ï¸ ResoluciÃ³n de Problemas

### Error de cÃ¡mara

```bash
# Probar la cÃ¡mara
python vision/camera.py
```

### Error de audio

```bash
# Verificar dispositivos de audio
python -c "import sounddevice as sd; print(sd.query_devices())"
```

### Error de Tesseract

```bash
# Verificar instalaciÃ³n
tesseract --version
```

### Error de modelo Vosk

- Verifica que el modelo estÃ© en `models/vosk-model-small-es-0.42/`
- Descarga de nuevo si es necesario

---

## ğŸ“ Estructura del Proyecto

```
assistive_ai/
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ recognizer.py      # Reconocimiento de voz con Vosk
â”‚   â””â”€â”€ speaker.py         # SÃ­ntesis de voz (OpenAI/Coqui/Sistema)
â”œâ”€â”€ vision/
â”‚   â”œâ”€â”€ camera.py          # Captura de imÃ¡genes
â”‚   â”œâ”€â”€ ocr.py            # OCR (OpenAI/Tesseract)
â”‚   â””â”€â”€ describe.py       # DescripciÃ³n de imÃ¡genes (OpenAI)
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ internet.py       # VerificaciÃ³n de conectividad
â”œâ”€â”€ models/               # Modelos Vosk
â”œâ”€â”€ temp/                 # Archivos temporales
â”œâ”€â”€ config.py            # ConfiguraciÃ³n general
â”œâ”€â”€ main.py              # AplicaciÃ³n principal
â”œâ”€â”€ commands.json        # Comandos personalizables
â””â”€â”€ requirements.txt     # Dependencias
```

---

## ğŸ”® CaracterÃ­sticas Avanzadas

- **Reconocimiento fuzzy:** Entiende comandos aunque no sean exactos
- **EjecuciÃ³n concurrente:** MÃºltiples comandos con control de concurrencia  
- **Limpieza automÃ¡tica:** Elimina archivos temporales automÃ¡ticamente
- **Fallback inteligente:** Cambia de mÃ©todo segÃºn disponibilidad
- **ConfiguraciÃ³n flexible:** FÃ¡cil personalizaciÃ³n sin tocar cÃ³digo

---

## ğŸ“‹ Dependencias Principales

```txt
vosk>=0.3.45
sounddevice>=0.4.6
opencv-python>=4.8.0
pytesseract>=0.3.10
requests>=2.31.0
TTS>=0.22.0
```

---

## ğŸ¯ Casos de Uso

1. **Lectura de documentos:** Facturas, cartas, menÃºs, etiquetas
2. **DescripciÃ³n de entorno:** Identificar objetos, personas, texto
3. **NavegaciÃ³n asistida:** DescripciÃ³n de espacios y obstÃ¡culos
4. **Accesibilidad diaria:** Herramienta de independencia personal

---

## ğŸš§ Limitaciones Actuales  

- La descripciÃ³n de escenas requiere conexiÃ³n a internet
- OpenAI TTS y OCR requieren clave API (con lÃ­mites de uso)
- El modelo Vosk puede tener dificultades con acentos muy marcados
- La calidad del OCR depende de la iluminaciÃ³n y calidad de imagen
